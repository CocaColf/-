---
layout: post
title: 用Node写了个爬虫
date: 2017/12/28
categories: Node.js
---
&#160;&#160;&#160;&#160;很喜欢Node，可是学了一点时间啊总觉得学不会，果然尽管都是js，但实际上几乎是不一样的东西。学来学去就是在看API，可能是我学习的方式不对吧？
&#160;&#160;&#160;&#160;上午写了点PHP，实在是写得无聊，下午寻思着写点啥，忽然想到爬虫这种东西，于是去网上看了看Node怎么写爬虫，看了会便开写。Node爬虫很简单，就是用`http模块`里的`request`方法，给它一个`hostname`和`path`就好。但简单的背后也有一些坑，首先我爬的是淘宝

```js
let req = http.request({
    hostname: 'www.taobao.com',
    path: '/../..'
}, res=>{
    var arr = [];
    res.on('data', buffer=>{
        arr.push(buffer);
    });
    res.on('end',()=>{
        let b = Buffer.concat(arr);
        fs.writeFile('tb.html', b);
    });
});
req.end();
```
**使用Buffer**
&#160;&#160;&#160;&#160;刚开始这里就有几个小坑，现在抓取的只是网页，那么的确是可以抓下来；如果是抓取一张图片资源，那么用数组保存最后得到的是一个照片软件打不开的资源，这就是为什么使用了`Buffer`。

**重定向**
&#160;&#160;&#160;&#160;当然，不能每次爬取的时候都手动去分离hostname和path，这时候就要用到`url模块`；然后再把抓取的整个过程封装成一个函数，这样每次只需要在把要抓取的地址传入函数即可。
&#160;&#160;&#160;&#160;在爬天猫的时候发现，并不能爬取数据，去看状态码发现是302，如果继续使用`res.headers.location`去爬，得到的是同样的结果，好家伙，还有这么一手啊，于是我想看看到底会有多少次重定向才会发现真身，先定义一个计数变量index，然后在每次抓取之后对返回的`header`里的状态码进行判断，如果是302或者301，那么就进行递归调用，地址是`res.header.location`。如果状态码是200，则抓取数据。

**网站的charset**
&#160;&#160;&#160;&#160;有时候当抓取一个网页下来，发现都是乱码，这时候实际上是编码格式的问题，Node使用的是utf-8编码，有些网站是gbk，所以这时候要用到`gbk模块`先把数据转化成utf8在进行抓取。

**虚拟DOM**
&#160;&#160;&#160;&#160;还有一种情况就是，需要抓取的是整个页面里的某个部分，这时候就不得不操作DOM了，找到了一个`jsdom模块`，可以在windows下模拟DOM操作。

源码在github
